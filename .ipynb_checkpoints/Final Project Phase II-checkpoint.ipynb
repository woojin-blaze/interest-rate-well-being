{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJ4Xt1uf1LT7"
   },
   "source": [
    "# Final Project Phase 2 Summary\n",
    "This Jupyter Notebook (.ipynb) will serve as the skeleton file for your submission for Phase 2 of the Final Project. Answer all statements addressed below as specified in the instructions for the project, covering all necessary details. Please be clear and concise in your answers. Each response should be at most 3 sentences. Good luck! <br><br>\n",
    "\n",
    "Note: To edit a Markdown cell, double-click on its text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woojin Kang (gtid: 904059831)\n",
    "SaiBalaji Nagarajan (gtid: 903935832)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjB_SbWY1LUB"
   },
   "source": [
    "## Jupyter Notebook Quick Tips\n",
    "Here are some quick formatting tips to get you started with Jupyter Notebooks. This is by no means exhaustive, and there are plenty of articles to highlight other things that can be done. We recommend using HTML syntax for Markdown but there is also Markdown syntax that is more streamlined and might be preferable. \n",
    "<a href = \"https://towardsdatascience.com/markdown-cells-jupyter-notebook-d3bea8416671\">Here's an article</a> that goes into more detail. (Double-click on cell to see syntax)\n",
    "\n",
    "# Heading 1\n",
    "## Heading 2\n",
    "### Heading 3\n",
    "#### Heading 4\n",
    "<br>\n",
    "<b>BoldText</b> or <i>ItalicText</i>\n",
    "<br> <br>\n",
    "Math Formulas: $x^2 + y^2 = 1$\n",
    "<br> <br>\n",
    "Line Breaks are done using br enclosed in < >.\n",
    "<br><br>\n",
    "Hyperlinks are done with: <a> https://www.google.com </a> or \n",
    "<a href=\"http://www.google.com\">Google</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tb9oVjpRDswQ"
   },
   "source": [
    "# Data Collection and Cleaning\n",
    "You are required to provide data collection and cleaning for the three (3) minimum datasets. Create a function for each of the following sections that reads or scrapes data from a file or website, manipulate and cleans the parsed data, and writes the cleaned data into a new file. \n",
    "\n",
    "Make sure your data cleaning and manipulation process is not too simple. Performing complex manipulation and using modules not taught in class shows effort, which will increase the chance of receiving full credit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Dp7Pm-Suh3d"
   },
   "source": [
    "## Data Sources\n",
    "Include sources (as links) to your datasets. Add any additional data sources if needed. Clearly indicate if a data source is different from one submitted in your Phase I, as we will check that it satisfies the requirements.\n",
    "*   Downloaded Dataset Source: https://data-explorer.oecd.org/vis?tm=wealth&pg=0&snb=160&df[ds]=dsDisseminateFinalDMZ&df[id]=DSD_HSL%40DF_HSL_CWB&df[ag]=OECD.WISE.WDP&df[vs]=1.0&dq=..._T._T._T.&pd=2004%2C2024&to[TIME_PERIOD]=false\n",
    "*   Web Collection #1 Source (DIFFERENT FROM ONE SUBMITTED IN PHASE 1): https://en.wikipedia.org/wiki/List_of_countries_by_Human_Development_Index#cite_note-olddata-19\n",
    "*   Web Collection #2 Source(JSON API): https://stats.bis.org/api/v2/data/dataflow/BIS/WS_CBPOL/1.0/M.AR+AU+BR+CA+CH+CL+CN+CO+CZ+DK+GB+HK+HR+HU+ID+IL+IN+IS+JP+KR+MA+MK+MX+MY+NO+NZ+PE+PH+PL+RO+RS+RU+SA+SE+TH+TR+US+XM+ZA?startPeriod=1990-01-01&endPeriod=2024-10-31&format=sdmx-json\n",
    "*   Web Collection #3 Source(JSON API): https://stats.bis.org/api/v2/data/dataflow/BIS/WS_CBTA/1.0/M.AE+AR+AT+AU+BE+BR+CA+CH+CL+CN+CZ+DE+DK+EE+ES+FI+FR+GB+GR+HK+HR+HU+ID+IE+IL+IN+IT+JP+KR+LT+LU+LV+MK+MX+MY+NL+NO+NZ+PE+PH+PL+PT+SA+SE+SG+SI+SK+TH+TR+US+XM+ZA..USD?startPeriod=1990-01-01&endPeriod=2024-10-30&format=sdmx-json , https://stats.bis.org/api/v2/data/dataflow/BIS/WS_CBTA/1.0/M.US..XDC..B?startPeriod=1990-01-01&endPeriod=2024-10-31&format=sdmx-json\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mRjxZDbE1tj"
   },
   "source": [
    "## Downloaded Dataset Requirement\n",
    "\n",
    "Fill in the predefined functions with your data scraping/parsing code. You may modify/rename each function as you seem fit, but you must provide at least 3 separate functions that clean each of your required datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pprint\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "executionInfo": {
     "elapsed": 685,
     "status": "error",
     "timestamp": 1617421302487,
     "user": {
      "displayName": "Bohong Cheng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh9YrzBjDpMd1KMv6KhO1wXCLX0XnbNKeDk0tkAgA=s64",
      "userId": "07627097596832814931"
     },
     "user_tz": 240
    },
    "id": "0p5xxmqzFGrO",
    "outputId": "efbb7221-19b9-4bb7-e5d3-302f144b257f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Country  Year  Disposable_Income\n",
      "0       DEU  2004            36965.0\n",
      "1       DEU  2005            37285.0\n",
      "2       DEU  2006            37745.0\n",
      "3       DEU  2007            37893.0\n",
      "4       DEU  2008            38311.0\n",
      "..      ...   ...                ...\n",
      "607     SWE  2018            38632.0\n",
      "608     SWE  2019            38821.0\n",
      "609     SWE  2020            38166.0\n",
      "610     SWE  2021            39404.0\n",
      "611     SWE  2022            39048.0\n",
      "\n",
      "[612 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def data_parser():\n",
    "  df = pd.read_csv(\"unfiltered_oecd_data.csv\")\n",
    "  disposable_income = data_select(df, \"1_1\")\n",
    "  disposable_income = cleaning_sub_table(disposable_income, \"Disposable_Income\")\n",
    "  disposable_income.to_csv(\"disposable_income.csv\", index = False)\n",
    "  pprint.pprint(disposable_income)\n",
    "\n",
    "def data_select(df, data_category):\n",
    "  df = df.loc[(df[\"MEASURE\"] == data_category) & (df[\"AGE\"] == \"_T\") & (df[\"SEX\"]==\"_T\") &(df[\"EDUCATION_LEV\"]==\"_T\"),[\"REF_AREA\", \"UNIT_MEASURE\", \"TIME_PERIOD\", \"OBS_VALUE\", \"OBS_STATUS\", \"DECIMALS\", \"BASE_PER\"]] \n",
    "  return df\n",
    "\n",
    "def cleaning_sub_table(data, measure):\n",
    "    data = data.loc[:, [\"REF_AREA\",\"TIME_PERIOD\", \"OBS_VALUE\"]]\n",
    "    data = data.reset_index(drop=True)\n",
    "    data = data.rename(columns= {\"OBS_VALUE\":measure, \"REF_AREA\":\"Country\", \"TIME_PERIOD\": \"Year\"})\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "############ Function Call ############\n",
    "data_parser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "794L4vGXFdYw"
   },
   "source": [
    "## Web Collection Requirement \\#1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "vXwpJObDFiWM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Rank      Country or territory HDI value  %annual growth(2010–2022)\n",
      "0      1               Switzerland     0.967                     0.0024\n",
      "1      2                    Norway     0.966                     0.0025\n",
      "2      3                   Iceland     0.959                     0.0028\n",
      "3      4                 Hong Kong     0.956                     0.0038\n",
      "4      5                   Denmark     0.952                     0.0035\n",
      "..   ...                       ...       ...                        ...\n",
      "161  188                      Mali     0.410                     0.0008\n",
      "162  189                     Niger     0.394                     0.0134\n",
      "163  191  Central African Republic     0.387                     0.0067\n",
      "164  192               South Sudan     0.381                     0.0053\n",
      "165  193                   Somalia     0.380                     0.0000\n",
      "\n",
      "[166 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def web_parser1():\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_countries_by_Human_Development_Index'\n",
    "    df = collect_data(url)\n",
    "    cleaned_df = clean_data(df)\n",
    "    export_data(cleaned_df)\n",
    "\n",
    "\n",
    "# Function to collect table data\n",
    "def collect_data(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    tables = soup.find_all(\"table\", {\"class\": \"wikitable\"})\n",
    "    second_table = tables[1]\n",
    "\n",
    "    header_cells = second_table.find_all(\"th\")\n",
    "    headers = [header_cells[i].text.strip() for i in range(min(5, len(header_cells)))]\n",
    "\n",
    "\n",
    "    rows = []\n",
    "    for row in second_table.find_all(\"tr\"):\n",
    "        cells = row.find_all([\"th\", \"td\"])  \n",
    "        cell_data = [cell.get_text(strip=True) for cell in cells]\n",
    "        if len(cell_data) >= 5 and cell_data[0] != \"Rank\":\n",
    "            rows.append(cell_data)\n",
    "            \n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "    return df\n",
    "\n",
    "def clean_data(df):\n",
    "    #Remove Delta column\n",
    "    df = df.drop(columns=[\"Δ\"], axis=1)\n",
    "\n",
    "    percent_columns = df.columns[df.columns.str.contains(\"%\")]\n",
    "    \n",
    "    for col in percent_columns:\n",
    "        #Remove % Symbol and NA values\n",
    "        df[col] = df[col].replace({\"%\": \"\", r\"NA\\[[a-c]\\]\": \"0\"}, regex=True)\n",
    "\n",
    "        #Format percentage into float\n",
    "        df[col] = df[col].astype(float) / 100\n",
    "    return df\n",
    "def export_data(df):\n",
    "    df.to_csv(\"HDI_output_file.csv\", index=False)\n",
    "    print(df)\n",
    "\n",
    "\n",
    "############ Function Call ############\n",
    "web_parser1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDD6sMsCXRxc"
   },
   "source": [
    "## Web Collection Requirement \\#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "HAkUOqMgXQJG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Country     Date  Total Asset\n",
      "0          PH  2000-01        23.13\n",
      "1          PH  2000-02        22.90\n",
      "2          PH  2000-03        24.47\n",
      "3          PH  2000-04        24.90\n",
      "4          PH  2000-05        24.81\n",
      "...       ...      ...          ...\n",
      "14791      US  2024-03      7484.74\n",
      "14792      US  2024-04      7402.43\n",
      "14793      US  2024-05      7284.32\n",
      "14794      US  2024-06      7231.16\n",
      "14795      US  2024-07      7178.39\n",
      "\n",
      "[14785 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def web_parser2():\n",
    "  urls = [\"https://stats.bis.org/api/v2/data/dataflow/BIS/WS_CBTA/1.0/M.AE+AR+AT+AU+BE+BR+CA+CH+CL+CN+CZ+DE+DK+EE+ES+FI+FR+GB+GR+HK+HR+HU+ID+IE+IL+IN+IT+JP+KR+LT+LU+LV+MK+MX+MY+NL+NO+NZ+PE+PH+PL+PT+SA+SE+SG+SI+SK+TH+TR+US+XM+ZA..USD?startPeriod=2000-01-01&endPeriod=2024-10-01&format=sdmx-json\",\n",
    "        \"https://stats.bis.org/api/v2/data/dataflow/BIS/WS_CBTA/1.0/M.US..XDC..B?startPeriod=2000-01-01&endPeriod=2024-10-01&format=sdmx-json\"]\n",
    "\n",
    "  data = [json.loads(requests.get(url).content) for url in urls]\n",
    "  country_abbv = get_country_abbv(data)\n",
    "  country_list = get_countries(country_abbv)\n",
    "  total_asset_dict = get_total_asset(data, country_list)\n",
    "  df = match_total_asset_date(total_asset_dict)\n",
    "  df = clean_null(df)\n",
    "  df.to_csv('total_assets_monthly.csv', index=False)\n",
    "  pprint.pprint(df)\n",
    "  \n",
    "def get_country_abbv(data):\n",
    "  country_abbv = []\n",
    "  for i, val in enumerate(data):\n",
    "    for item in data[i][\"data\"][\"structure\"][\"dimensions\"][\"series\"][1]['values']:\n",
    "        country_abbv.append(item)\n",
    "  return country_abbv\n",
    "\n",
    "def get_countries(country_abbv):\n",
    "  country_list = []\n",
    "  for item in country_abbv: \n",
    "      country_list.append(item[\"id\"])\n",
    "  return country_list\n",
    "\n",
    "def get_total_asset(data, country_list):\n",
    "  new_list = []\n",
    "  for i, val in enumerate(data):\n",
    "      for key, value in data[i][\"data\"][\"dataSets\"][0][\"series\"].items():\n",
    "          alist = []\n",
    "          for k, val in value[\"observations\"].items():\n",
    "              alist.append(val[0])\n",
    "          new_list.append(alist)\n",
    "  total_asset_dict = dict(zip(country_list, new_list))\n",
    "  return total_asset_dict\n",
    "\n",
    "def match_total_asset_date(total_asset_dict):\n",
    "  dates = pd.date_range(start=\"2000-01\", end=\"2024-10\", freq='MS') \n",
    "  rows = []\n",
    "  for country, values in total_asset_dict.items():\n",
    "      for date, value in zip(dates, values):\n",
    "          rows.append({'Country': country, 'Date': date.strftime(\"%Y-%m\"), 'Total Asset': round(float(value), 2)})\n",
    "\n",
    "  df = pd.DataFrame(rows)\n",
    "  return df\n",
    "\n",
    "def clean_null(df):\n",
    "  df[df.isnull().any(axis=1)]\n",
    "  df = df.dropna()\n",
    "  return df\n",
    "\n",
    "        \n",
    "############ Function Call ############\n",
    "web_parser2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezovwa1tp0we"
   },
   "source": [
    "## Additional Dataset Parsing/Cleaning Functions\n",
    "\n",
    "Write any supplemental (optional) functions here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "f4-s72RNuKLR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Country     Date  Interest Rate\n",
      "0          DK  2000-01           3.30\n",
      "1          DK  2000-02           3.60\n",
      "2          DK  2000-03           3.85\n",
      "3          DK  2000-04           4.10\n",
      "4          DK  2000-05           4.10\n",
      "...       ...      ...            ...\n",
      "11293      CL  2024-06           5.75\n",
      "11294      CL  2024-07           5.75\n",
      "11295      CL  2024-08           5.75\n",
      "11296      CL  2024-09           5.50\n",
      "11297      CL  2024-10           5.25\n",
      "\n",
      "[11245 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def extra_source1():\n",
    "  urls = [\"https://stats.bis.org/api/v2/data/dataflow/BIS/WS_CBPOL/1.0/M.AR+AU+BR+CA+CH+CL+CN+CO+CZ+DK+GB+HK+HR+HU+ID+IL+IN+IS+JP+KR+MA+MK+MX+MY+NO+NZ+PE+PH+PL+RO+RS+RU+SA+SE+TH+TR+US+XM+ZA?startPeriod=2000-01-01&endPeriod=2024-10-01&format=sdmx-json\"]\n",
    "  data = [json.loads(requests.get(url).content) for url in urls]\n",
    "  country_abbv = get_country_abbv(data)\n",
    "  country_list = get_countries(country_abbv)\n",
    "  interest_rate_dict = get_interest_rate(data, country_list)\n",
    "  df = match_interest_rate_date(interest_rate_dict)\n",
    "  df = clean_null(df)\n",
    "  df.to_csv('interest_rate_monthly.csv', index=False)\n",
    "  pprint.pprint(df)\n",
    "  \n",
    "def get_country_abbv(data):\n",
    "  country_abbv = []\n",
    "  for i, val in enumerate(data):\n",
    "    for item in data[i][\"data\"][\"structure\"][\"dimensions\"][\"series\"][1]['values']:\n",
    "        country_abbv.append(item)\n",
    "  return country_abbv\n",
    "\n",
    "def get_countries(country_abbv):\n",
    "  country_list = []\n",
    "  for item in country_abbv: \n",
    "      country_list.append(item[\"id\"])\n",
    "  return country_list\n",
    "\n",
    "def get_interest_rate(data, country_list):\n",
    "  new_list = []\n",
    "  for i, val in enumerate(data):\n",
    "      for key, value in data[i][\"data\"][\"dataSets\"][0][\"series\"].items():\n",
    "          alist = []\n",
    "          for k, val in value[\"observations\"].items():\n",
    "              alist.append(val[0])\n",
    "          new_list.append(alist)\n",
    "  interest_rate_dict = dict(zip(country_list, new_list))\n",
    "  return interest_rate_dict\n",
    "\n",
    "def match_interest_rate_date(nterest_rate_dict):\n",
    "  dates = pd.date_range(start=\"2000-01\", end=\"2024-10\", freq='MS') \n",
    "  rows = []\n",
    "  for country, values in nterest_rate_dict.items():\n",
    "      for date, value in zip(dates, values):\n",
    "          rows.append({'Country': country, 'Date': date.strftime(\"%Y-%m\"), 'Interest Rate': round(float(value), 3)})\n",
    "\n",
    "  df = pd.DataFrame(rows)\n",
    "  return df\n",
    "\n",
    "def clean_null(df):\n",
    "  df[df.isnull().any(axis=1)]\n",
    "  df = df.dropna()\n",
    "  return df\n",
    "    \n",
    "############ Function Call ############\n",
    "extra_source1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "yB3qXt_XuY7b"
   },
   "outputs": [],
   "source": [
    "# Define further extra source functions as necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uttEYrm9US5s"
   },
   "source": [
    "# Inconsistencies\n",
    "\n",
    "For each inconsistency (NaN, null, duplicate values, empty strings, etc.) you discover in your datasets, write at least 2 sentences stating the significance, how you identified it, and how you handled it.\n",
    "\n",
    "1. Source 1 contained 3 missing values (NA) for the column titled growth. The reason stated for this was that data did not exist for the previous year, therefore we assumed growth to be 0 and replaced these values with 0.\n",
    "\n",
    "2. Source 1 contained a column containing percentage data that was formatted as a string with a \"%\" at the end of it. We needed to reformat this column to use it for analysis and we did so by removing the % symbol, converting to float, and dividing by 100.\n",
    "\n",
    "3. Source 2 contained countless Null Values across many columns. All null values were dropped altogether as many null values usually occured in the same row and made the row itself useless for analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "591923e582065aff74a93a90fba3a50741a602c305cc24a3d29844b7d540dc83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
